{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Label images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use labelme or something to label the image set you've got. Images should be labelled with different classes and each class has a unique id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classdict = {\n",
    "    \"liner\": 0,\n",
    "    \"bulk carrier\": 1,\n",
    "    \"warship\": 2,\n",
    "    \"sailboat\": 3,\n",
    "    \"canoe\": 4,\n",
    "    \"container ship\": 5,\n",
    "    \"fishing boat\": 6\n",
    "} # How I set Infrared-Ocean-Target images' classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Orgnize structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After labeling the images, your dataset structure should look like this:\n",
    "\n",
    "```\n",
    "RawDataset/\n",
    "├── annotations/\n",
    "│   ├── 1_1.xml\n",
    "│   └── 1_3.xml\n",
    "└── images/\n",
    "    ├── 1_1.jpg\n",
    "    └── 1_3.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdataset_dir = './RawDataset' # rawdataset rootdir\n",
    "labels_dir = f'{rawdataset_dir}/annotations' # rootdir/xmldir\n",
    "images_dir = f'{rawdataset_dir}/images' # rootdir/jpgdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the ultralytic's offical document, our final dataset structure should look like this:\n",
    "\n",
    "```\n",
    "Dataset/\n",
    "├── train/\n",
    "│   ├── images/\n",
    "│   │   └── 1_1.txt\n",
    "│   └── labels/\n",
    "│       └── 1_1.jpg\n",
    "└── val/\n",
    "    ├── images/\n",
    "    │   └── 1_3.txt\n",
    "    └── labels/\n",
    "        └── 1_3.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './Dataset' # dataset rootdir\n",
    "dataset_dir_train = f'{dataset_dir}/train' # rootdir/traindir\n",
    "dataset_dir_val = f'{dataset_dir}/val' # rootdir/valdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To divide dataset, we usually first shuffle the files and then divide them by ratio of 7:3 (7 for train anf 3 for validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "xmlfiles = [Path(labels_dir).joinpath(f).as_posix() for f in os.listdir(labels_dir) if f.endswith('.xml')]\n",
    "#imagefiles = [Path(images_dir).joinpath(f).as_posix() for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
    "\n",
    "random.shuffle(xmlfiles)\n",
    "\n",
    "TrainSize = int(len(xmlfiles) * 0.7)\n",
    "xmlFiles_Train = xmlfiles[:TrainSize]\n",
    "xmlFiles_Val = xmlfiles[TrainSize:]\n",
    "\n",
    "jpgFiles_Train = [Path(images_dir).joinpath(os.path.basename(f).replace('xml', 'jpg')).as_posix() for f in xmlFiles_Train]\n",
    "jpgFiles_Val = [Path(images_dir).joinpath(os.path.basename(f).replace('xml', 'jpg')).as_posix() for f in xmlFiles_Val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert xml to txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the next step is to convert xml to txt with the following content format that yolo supported:\n",
    "\n",
    "```\n",
    "classid center_x center_y width height\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def convert_xml_to_yolotxt(classdict, xml_path, output_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    objects = root.findall('object')\n",
    "    size = root.find('size')\n",
    "    size_w = int(size.find('width').text)\n",
    "    size_h = int(size.find('height').text)\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        def calc(box, size_w, size_h):\n",
    "            x = (box[0] + box[2]) / 2.0\n",
    "            y = (box[1] + box[3]) / 2.0\n",
    "            w = box[2] - box[0]\n",
    "            h = box[3] - box[1]\n",
    "            x = x / size_w\n",
    "            y = y / size_h\n",
    "            w = w / size_w\n",
    "            h = h / size_h\n",
    "            return x, y, w, h\n",
    "        for obj in objects:\n",
    "            classid = obj.find('name').text\n",
    "            classid = classdict[classid]\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(bndbox.find('xmin').text)\n",
    "            ymin = int(bndbox.find('ymin').text)\n",
    "            xmax = int(bndbox.find('xmax').text)\n",
    "            ymax = int(bndbox.find('ymax').text)\n",
    "            box = (xmin, ymin, xmax, ymax)\n",
    "            center_x, center_y, width, height = calc(box, size_w, size_h)\n",
    "            f.write(f\"{classid} {center_x} {center_y} {width} {height}\\n\")\n",
    "\n",
    "\n",
    "for xmlfile in xmlFiles_Train:\n",
    "    labelsoutput_dir_train = Path(dataset_dir_train).joinpath('labels').as_posix()\n",
    "    os.makedirs(labelsoutput_dir_train, exist_ok = True)\n",
    "    convert_xml_to_yolotxt(\n",
    "        classdict,\n",
    "        xmlfile,\n",
    "        Path(labelsoutput_dir_train).joinpath(os.path.basename(xmlfile).split('.')[0] + '.txt').as_posix()\n",
    "    )\n",
    "\n",
    "for xmlfile in xmlFiles_Val:\n",
    "    labelsoutput_dir_val = Path(dataset_dir_val).joinpath('labels').as_posix()\n",
    "    os.makedirs(labelsoutput_dir_val, exist_ok = True)\n",
    "    convert_xml_to_yolotxt(\n",
    "        classdict,\n",
    "        xmlfile,\n",
    "        Path(labelsoutput_dir_val).joinpath(os.path.basename(xmlfile).split('.')[0] + '.txt').as_posix()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Move images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EZ :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "for jpgfile in jpgFiles_Train:\n",
    "    imagesoutput_dir_train = Path(dataset_dir_train).joinpath('images').as_posix()\n",
    "    os.makedirs(imagesoutput_dir_train, exist_ok = True)\n",
    "    shutil.move(jpgfile, imagesoutput_dir_train)\n",
    "\n",
    "for jpgfile in jpgFiles_Val:\n",
    "    imagesoutput_dir_val = Path(dataset_dir_val).joinpath('images').as_posix()\n",
    "    os.makedirs(imagesoutput_dir_val, exist_ok = True)\n",
    "    shutil.move(jpgfile, imagesoutput_dir_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training, we still need a yaml file to help yolo load dataset correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset - Paths\n",
    "path = 'D:/YOLOv8-Basic-Tutorial/Dataset' # [essential] dataset root dir (better use absolute path to avoid error)\n",
    "train = 'train/images'  # [essential] train images (relative to 'path')\n",
    "val = 'val/images'  # [essential] val images (relative to 'path')\n",
    "\n",
    "# Dataset - Classes (Example)\n",
    "class0 = 'liner'\n",
    "class1 = 'bulk carrier'\n",
    "class2 = 'warship'\n",
    "class3 = 'sailboat'\n",
    "class4 = 'canoe'\n",
    "class5 = 'container ship'\n",
    "class6 = 'fishing boat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use python's yaml lib to create file. Note that the file should be located in your project's root dir (The same dir with training file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "yamldata = f'''\n",
    "# Note: This yaml file is created with python\n",
    "\n",
    "# Paths\n",
    "path: {path}\n",
    "train: {train}\n",
    "val: {val}\n",
    "\n",
    "# Classes (Example)\n",
    "names:\n",
    "  0: {class0}\n",
    "  1: {class1}\n",
    "  2: {class2}\n",
    "  3: {class3}\n",
    "  4: {class4}\n",
    "  5: {class5}\n",
    "  6: {class6}\n",
    "\n",
    "# Done\n",
    "'''\n",
    "\n",
    "with open('./Infrared-Ocean-Target.yaml', 'w', encoding = 'utf-8') as file:\n",
    "    yaml.dump(\n",
    "        yaml.safe_load(yamldata),\n",
    "        file,\n",
    "        default_flow_style = False,\n",
    "        allow_unicode = True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
